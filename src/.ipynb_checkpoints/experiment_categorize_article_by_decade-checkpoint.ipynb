{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats \n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "#change to appropriate path\n",
    "results_path = \"/Users/mark/Desktop/wiki_v4/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Article Title by Year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load Wikipedia First Link Network \n",
    "\n",
    "\n",
    "with open(results_path + \"fln.json\") as f:\n",
    "    fln_dict = json.load(f)\n",
    "fln_df = pd.DataFrame.from_dict(fln_dict, orient='index')\n",
    "fln_df.index.name = 'article'\n",
    "fln_df.columns = ['first link']\n",
    "fln_df = fln_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load Categories\n",
    "data_path = \"/Users/mark/Dropbox/Math/Complex_Systems/research/classifying-ideas/historical_wikipedia/data/\"\n",
    "with open(data_path + \"categories_for_words.json\") as f:\n",
    "    categories_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create list of categories\n",
    "categories_set = set([])\n",
    "for category_group in categories_dict.values():\n",
    "    categories_set = categories_set.union(set(category_group))\n",
    "\n",
    "categories_list = list(categories_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load word with years json\n",
    "\n",
    "with open(\"../data/words_with_years.json\") as dw:\n",
    "    word_years_dict = json.load(dw)\n",
    "    #default dict value of 2015\n",
    "    word_years_dict = defaultdict(lambda: 2015, word_years_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute year for article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_article_year(title):\n",
    "    \"\"\"\n",
    "    returns the earliest year\n",
    "    the article could have appeared\n",
    "    by computing the latest first \n",
    "    appearance of the words in the title\n",
    "    \"\"\"\n",
    "    years = []\n",
    "    for word in title.split():\n",
    "        years.append(word_years_dict[word.lower().strip(\"()\")])\n",
    "    years.sort()\n",
    "    if years:\n",
    "        return years[-1]\n",
    "    else:\n",
    "        return 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#apply function to dataframe (runtime ~3 min)\n",
    "fln_df['year'] = fln_df['article'].apply(get_article_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Category Rank by Decade\n",
    "\n",
    "* a word may appear in more than one category\n",
    "* a word appearing more than once in the title is not double counted in rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_article_categories(title):\n",
    "    \"\"\"\n",
    "    returns a dictionary of categories and their frequency \n",
    "    based on the words in the title \n",
    "        formatted as a dictionary: category --> frequency\n",
    "        words appearing more than once in the title are not double counted\n",
    "    \"\"\"\n",
    "    categories = defaultdict(int)\n",
    "    try:\n",
    "        for word in title.split():\n",
    "            #eliminate duplicates \n",
    "            word_categories = set(categories_dict.get(word.lower().strip(\"()\"), []))\n",
    "            for category in word_categories:\n",
    "                categories[category] += 1\n",
    "        if categories:\n",
    "            return categories\n",
    "        else:\n",
    "            return False\n",
    "    except AttributeError:\n",
    "        return False\n",
    "        \n",
    "len_categories = len(list(categories_set))\n",
    "\n",
    "def get_category_freq_list(title):\n",
    "    \"\"\"\n",
    "    returns a list of frequency count for each of the 371 categories\n",
    "    based on the title of the given article\n",
    "    \"\"\"\n",
    "    categories = get_article_categories(title)\n",
    "    freq_list = np.zeros(len_categories)\n",
    "    # confirm categories aren't empty\n",
    "    if categories:\n",
    "        for category, count in categories.items():\n",
    "            index = categories_list.index(category)\n",
    "            freq_list[index] += count\n",
    "    return freq_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'Ability': 1,\n",
       "             'Expectation': 1,\n",
       "             'Farming': 1,\n",
       "             'Knowledge': 1,\n",
       "             'Linguistics': 1,\n",
       "             'Naming': 1,\n",
       "             'Number': 1,\n",
       "             'Particular plants': 1,\n",
       "             'Study of work': 1})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_article_categories(\"apple computer the technology\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Category Frequency by article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>first link</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kangavar, East Azerbaijan</td>\n",
       "      <td>Kolah Boz-e Sharqi Rural District</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Noah Ponzer</td>\n",
       "      <td>Sandy Hook Elementary School shooting</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>List of colonial governors of South Carolina</td>\n",
       "      <td>Province of South Carolina</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jacobsdorf</td>\n",
       "      <td>Municipalities of Germany</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Battle of flarchheim</td>\n",
       "      <td>Battle of Flarchheim</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article  \\\n",
       "0                     Kangavar, East Azerbaijan   \n",
       "1                                   Noah Ponzer   \n",
       "2  List of colonial governors of South Carolina   \n",
       "3                                    Jacobsdorf   \n",
       "4                          Battle of flarchheim   \n",
       "\n",
       "                              first link  year  \n",
       "0      Kolah Boz-e Sharqi Rural District  2015  \n",
       "1  Sandy Hook Elementary School shooting  2015  \n",
       "2             Province of South Carolina  2015  \n",
       "3              Municipalities of Germany  2015  \n",
       "4                   Battle of Flarchheim  2015  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fln_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11277534, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fln_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Earnestown, Upper Canada'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fln_df.iloc[3][\"article\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 11277534)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(fln_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def yield_category_counts(fln_df):\n",
    "    num_rows = range(fln_df.shape[0])\n",
    "    for i in num_rows:\n",
    "        article = fln_df.iloc[i][\"article\"]\n",
    "        yield get_category_freq_list(article)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The occult',\n",
       " 'Of/pertaining to events/occurrences',\n",
       " 'Aspects of emotion',\n",
       " 'Wrongdoing',\n",
       " 'Difficulty',\n",
       " 'Military equipment',\n",
       " 'Frequency',\n",
       " 'Transfer of property',\n",
       " 'Inhabitant',\n",
       " 'Armed forces',\n",
       " 'Moral evil',\n",
       " 'Lack of power/authority',\n",
       " 'Enquiry',\n",
       " 'Working',\n",
       " 'People collectively',\n",
       " 'Earth science',\n",
       " 'Suffering',\n",
       " 'Reading',\n",
       " 'Love',\n",
       " 'Supply',\n",
       " 'Particular time',\n",
       " 'Industry',\n",
       " 'Failure/lack of success',\n",
       " 'Region of the earth',\n",
       " 'Buying',\n",
       " 'Necessity',\n",
       " 'Removing from dwelling',\n",
       " 'Trader',\n",
       " 'Chemistry',\n",
       " 'Motion in specific manner',\n",
       " 'Transport',\n",
       " 'War',\n",
       " 'Wholeness',\n",
       " 'Compassion',\n",
       " 'Fashionableness',\n",
       " 'Drill/training',\n",
       " 'Animals collectively',\n",
       " 'Punishment',\n",
       " 'Memory',\n",
       " 'In a ripening manner',\n",
       " 'Knowledge',\n",
       " 'Hearing/noise',\n",
       " 'Restlessness',\n",
       " 'Pride',\n",
       " 'Attention',\n",
       " 'Merchandise',\n",
       " 'Ethnicities',\n",
       " 'By family relationships',\n",
       " 'Trading conditions',\n",
       " 'Languages of the world',\n",
       " 'Variety/species',\n",
       " 'Office',\n",
       " 'Ill-health',\n",
       " 'Customs/values/civilization',\n",
       " 'Relationship',\n",
       " 'By nature',\n",
       " 'Providing with dwelling',\n",
       " 'Navigation',\n",
       " 'Bad taste',\n",
       " 'Causation',\n",
       " 'Possessions',\n",
       " 'Discovery',\n",
       " 'The paranormal',\n",
       " 'Bodily movement',\n",
       " 'Kind/sort',\n",
       " 'Duty/obligation',\n",
       " 'Barter',\n",
       " 'Furnishing with inhabitants',\n",
       " 'Calmness',\n",
       " 'Anthropocentrism',\n",
       " 'Suitable time/opportunity',\n",
       " 'Place of education',\n",
       " 'Study of society',\n",
       " 'Appearance of plant',\n",
       " 'Geodetic references',\n",
       " 'Healing/cure',\n",
       " 'Naming',\n",
       " 'Military power',\n",
       " 'By day or by night',\n",
       " 'Shape',\n",
       " 'Water',\n",
       " 'Brokerage',\n",
       " 'Position/job',\n",
       " 'Correspondence',\n",
       " 'Intelligibility',\n",
       " 'Rightness/justice',\n",
       " 'Fees and taxes',\n",
       " 'Poverty',\n",
       " 'Violent emotion',\n",
       " 'Locomotive',\n",
       " 'Advantage',\n",
       " 'Undertaking',\n",
       " 'Acquisition',\n",
       " 'Source/principle of life',\n",
       " 'Invertebrates',\n",
       " 'Thought',\n",
       " 'Social event',\n",
       " 'Business affairs',\n",
       " 'Amending',\n",
       " 'Zeal/enthusiasm',\n",
       " 'Legal document',\n",
       " 'Biology',\n",
       " 'Branch of the law',\n",
       " 'Payment',\n",
       " 'Food',\n",
       " 'Touch/feeling',\n",
       " 'Part of plant',\n",
       " 'Ability',\n",
       " 'Drink',\n",
       " 'Inattention',\n",
       " 'Humility',\n",
       " 'Worker',\n",
       " 'Rate of motion',\n",
       " 'Military operations',\n",
       " 'Entertainment',\n",
       " 'Cleanness/dirtiness',\n",
       " 'Work',\n",
       " 'Repeating',\n",
       " 'Motion in a certain direction',\n",
       " 'With reference to rights/obligations',\n",
       " 'Impact',\n",
       " 'Possessor',\n",
       " 'Lack of understanding',\n",
       " 'Broadcasting',\n",
       " 'Written laws',\n",
       " 'Sleeping and waking',\n",
       " 'Specific types of trade',\n",
       " 'Study of work',\n",
       " 'Clothing',\n",
       " 'Lack of subjection',\n",
       " 'Record',\n",
       " 'Money',\n",
       " 'Legal power',\n",
       " 'Fear',\n",
       " 'Upbringing',\n",
       " 'A language',\n",
       " 'Unfashionableness',\n",
       " 'Contempt',\n",
       " 'Expectation',\n",
       " 'Passion',\n",
       " 'Mammals',\n",
       " 'Measurement',\n",
       " 'Alchemy',\n",
       " 'Workplace',\n",
       " 'Transference',\n",
       " 'Direction',\n",
       " 'Giving',\n",
       " 'Behaviour',\n",
       " 'Jealousy/envy',\n",
       " 'Other trading methods',\n",
       " 'Aspects of travel',\n",
       " 'That feeds',\n",
       " 'Illegal/immoral trading',\n",
       " 'Free will',\n",
       " 'Smell/odour',\n",
       " 'Command',\n",
       " 'Spending time',\n",
       " 'Dancing',\n",
       " 'Selling',\n",
       " 'Hostilities at sea',\n",
       " 'Change',\n",
       " 'Monetary value',\n",
       " 'The body',\n",
       " 'Adversity',\n",
       " 'Minerals',\n",
       " 'Nations',\n",
       " 'Perception/cognition',\n",
       " 'Understanding',\n",
       " 'Writing',\n",
       " 'Social class',\n",
       " 'Zoology',\n",
       " 'The universe',\n",
       " 'Defence',\n",
       " 'Subjection',\n",
       " 'Sport',\n",
       " 'Beauty',\n",
       " 'Badness/evil',\n",
       " 'Control',\n",
       " 'Lack of beauty',\n",
       " 'Legal obligation',\n",
       " 'Colour',\n",
       " 'Hatred',\n",
       " 'Absence of movement',\n",
       " 'Representation',\n",
       " 'Lack of work',\n",
       " 'Judgement, decision',\n",
       " 'By habits/actions',\n",
       " 'Extension in space',\n",
       " 'Amphibians',\n",
       " 'Member of university',\n",
       " 'Of/pertaining to birds',\n",
       " 'Financial dealings',\n",
       " 'Book',\n",
       " 'Virtue',\n",
       " 'Excitement',\n",
       " 'Materials',\n",
       " 'Dueness/propriety',\n",
       " 'Use of drugs, poison',\n",
       " 'Relative time',\n",
       " 'Inaction',\n",
       " 'Statement',\n",
       " 'Distance',\n",
       " 'Aspects of faith',\n",
       " 'Legal possession',\n",
       " 'By noises',\n",
       " 'Social attitudes',\n",
       " 'Continuing',\n",
       " 'Pleasure',\n",
       " 'Absence of emotion',\n",
       " 'Anger',\n",
       " 'Light',\n",
       " 'Quantity',\n",
       " 'Rule/government',\n",
       " 'Peace',\n",
       " 'Non-possession',\n",
       " 'Good taste',\n",
       " 'Indication',\n",
       " 'Number',\n",
       " 'Information',\n",
       " 'Warriors collectively',\n",
       " 'Deity',\n",
       " 'Printing',\n",
       " 'Stocks and shares',\n",
       " 'Legal profession',\n",
       " 'Telecommunication',\n",
       " 'Completing',\n",
       " 'Answer',\n",
       " 'Trading place',\n",
       " 'Intellect',\n",
       " 'Military service',\n",
       " 'Of/pertaining to an instrument for measuring time',\n",
       " 'Sexual',\n",
       " 'Rule of law',\n",
       " 'Social relations',\n",
       " 'The Arts',\n",
       " 'Quality of being good',\n",
       " 'Rail travel',\n",
       " 'Learning',\n",
       " 'Inhabited place',\n",
       " 'Safety',\n",
       " 'Testing',\n",
       " 'Liquid',\n",
       " 'Expression',\n",
       " 'Period',\n",
       " 'Intention',\n",
       " 'Decision',\n",
       " 'Sight/vision',\n",
       " 'Kinship/relationship',\n",
       " 'Ceasing',\n",
       " 'Harmfulness',\n",
       " 'Particular plants',\n",
       " 'Teaching',\n",
       " 'Artefacts',\n",
       " 'Growing/that grows',\n",
       " 'Esteem',\n",
       " 'Disposition/character',\n",
       " 'Charges',\n",
       " 'Attractiveness',\n",
       " 'Relative position',\n",
       " 'Attack',\n",
       " 'Pertaining to animal body',\n",
       " 'Endeavour',\n",
       " 'Order',\n",
       " 'Harm/detriment',\n",
       " 'Gas',\n",
       " 'Consciousness',\n",
       " 'Armed encounter',\n",
       " 'Philosophy',\n",
       " 'Importance',\n",
       " 'Church government',\n",
       " 'Structure of the earth',\n",
       " 'Loss',\n",
       " 'Person',\n",
       " 'State of being accursed',\n",
       " 'Wish/inclination',\n",
       " 'Vertebrates',\n",
       " 'By habitat',\n",
       " 'Management of money',\n",
       " 'Importing/exporting',\n",
       " 'Lack of strictness',\n",
       " 'Dissent',\n",
       " 'Aesthetics',\n",
       " 'Beautification',\n",
       " 'Physics',\n",
       " 'Existence',\n",
       " 'Strictness',\n",
       " 'Inhabiting a type of place',\n",
       " 'Sharing',\n",
       " 'Retaining',\n",
       " 'Educational administration',\n",
       " 'Condition of matter',\n",
       " 'Operation upon something',\n",
       " 'Journalism',\n",
       " 'Constitution of matter',\n",
       " 'Mental health/sanity',\n",
       " 'Belief',\n",
       " 'Prosperity',\n",
       " 'Defeat',\n",
       " 'Manner of action',\n",
       " 'Fish',\n",
       " 'Plants collectively',\n",
       " 'Air/space travel',\n",
       " 'Bargaining',\n",
       " 'Indifference',\n",
       " 'Courage',\n",
       " 'By nutrition/respiration',\n",
       " 'Be wild',\n",
       " 'Death',\n",
       " 'Progressive motion',\n",
       " 'Gratitude',\n",
       " 'Reckoning of time',\n",
       " 'Sincere emotion',\n",
       " 'Science of mankind',\n",
       " 'Wealth',\n",
       " 'Be diseased/injured/discoloured',\n",
       " 'Psychology',\n",
       " 'Creation',\n",
       " 'Speech',\n",
       " 'Jurisprudence',\n",
       " 'Study of law',\n",
       " 'Place',\n",
       " 'Ability to be perceived by senses',\n",
       " 'Warrior',\n",
       " 'Legislation',\n",
       " 'System of laws',\n",
       " 'Impelling/driving',\n",
       " 'Named regions of earth',\n",
       " 'Malediction',\n",
       " 'Administration of justice',\n",
       " 'Carrying out',\n",
       " 'Equipment',\n",
       " 'Manifestation',\n",
       " 'Atmosphere, weather',\n",
       " 'Inhabiting temporarily',\n",
       " 'Animals hunted',\n",
       " 'Duties',\n",
       " 'Owning',\n",
       " 'Intense',\n",
       " 'Properties of materials',\n",
       " 'Legal right',\n",
       " 'Family unit',\n",
       " 'Law enforcement',\n",
       " 'Taking',\n",
       " 'Belligerent',\n",
       " 'Trading organization',\n",
       " 'Power',\n",
       " 'Inhabit/colonize',\n",
       " 'Duration',\n",
       " 'Motivation',\n",
       " 'Inferiority/baseness',\n",
       " 'Legal capacity',\n",
       " 'Botany',\n",
       " 'Easiness',\n",
       " 'Supernatural being',\n",
       " 'Farming',\n",
       " 'Linguistics',\n",
       " 'Valued plants and weeds',\n",
       " 'Land',\n",
       " 'Sect',\n",
       " 'Textiles',\n",
       " 'Worship',\n",
       " 'Taste/flavour',\n",
       " 'Protohuman',\n",
       " 'Military organization',\n",
       " 'Domestic animal',\n",
       " 'Spirituality',\n",
       " 'Types of laws',\n",
       " 'Reptiles',\n",
       " 'Hunting',\n",
       " 'Means of travel',\n",
       " 'Chordates',\n",
       " 'Exercise of authority',\n",
       " 'Victory',\n",
       " 'Relinquishing',\n",
       " 'Doing',\n",
       " 'Attack with aircraft']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.166146</td>\n",
       "      <td>0.705149</td>\n",
       "      <td>0.557564</td>\n",
       "      <td>0.884386</td>\n",
       "      <td>1.985566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.530212</td>\n",
       "      <td>1.773549</td>\n",
       "      <td>0.276405</td>\n",
       "      <td>0.957895</td>\n",
       "      <td>0.401078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.674192</td>\n",
       "      <td>1.441262</td>\n",
       "      <td>0.924968</td>\n",
       "      <td>0.117663</td>\n",
       "      <td>2.155317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.212631</td>\n",
       "      <td>0.925633</td>\n",
       "      <td>0.551006</td>\n",
       "      <td>-0.485107</td>\n",
       "      <td>-0.997685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.383375</td>\n",
       "      <td>1.375042</td>\n",
       "      <td>0.384287</td>\n",
       "      <td>-0.503566</td>\n",
       "      <td>1.620084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.166672</td>\n",
       "      <td>-0.168069</td>\n",
       "      <td>-0.737490</td>\n",
       "      <td>-0.320284</td>\n",
       "      <td>0.497272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.471701</td>\n",
       "      <td>0.406183</td>\n",
       "      <td>0.111683</td>\n",
       "      <td>0.554170</td>\n",
       "      <td>0.049797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.268410</td>\n",
       "      <td>1.875699</td>\n",
       "      <td>0.418347</td>\n",
       "      <td>-0.108458</td>\n",
       "      <td>-1.854208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.366696</td>\n",
       "      <td>0.357469</td>\n",
       "      <td>1.191215</td>\n",
       "      <td>-1.162609</td>\n",
       "      <td>-1.005563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.224450</td>\n",
       "      <td>-0.191218</td>\n",
       "      <td>1.065470</td>\n",
       "      <td>1.312666</td>\n",
       "      <td>-0.674643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4\n",
       "0 -0.166146  0.705149  0.557564  0.884386  1.985566\n",
       "1 -1.530212  1.773549  0.276405  0.957895  0.401078\n",
       "2 -1.674192  1.441262  0.924968  0.117663  2.155317\n",
       "3  1.212631  0.925633  0.551006 -0.485107 -0.997685\n",
       "4 -1.383375  1.375042  0.384287 -0.503566  1.620084\n",
       "5 -0.166672 -0.168069 -0.737490 -0.320284  0.497272\n",
       "6 -1.471701  0.406183  0.111683  0.554170  0.049797\n",
       "7  1.268410  1.875699  0.418347 -0.108458 -1.854208\n",
       "8 -0.366696  0.357469  1.191215 -1.162609 -1.005563\n",
       "9  0.224450 -0.191218  1.065470  1.312666 -0.674643"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.random.randn(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                              Kangavar, East Azerbaijan\n",
       "1                                            Noah Ponzer\n",
       "2           List of colonial governors of South Carolina\n",
       "3                                             Jacobsdorf\n",
       "4                                   Battle of flarchheim\n",
       "5                                        Marco II Sanudo\n",
       "6                                Kedzierzyn-Kozle County\n",
       "7                                        Lake Nettilling\n",
       "8                                 London Buses route 499\n",
       "9                                         Cucamonga Peak\n",
       "10                                  The Bryan Adams band\n",
       "11                                        Ashley Feraude\n",
       "12                                          Prescott, MA\n",
       "13                                        Debra Lawrence\n",
       "14                       Texas Board of Criminal Justice\n",
       "15                                          U-ka Saegusa\n",
       "16                                     Carlos Blackaller\n",
       "17                                        Western A.F.C.\n",
       "18                                              Ultra 24\n",
       "19                                              Rob Jebb\n",
       "20                    South African Journal of Economics\n",
       "21                                 Generation set system\n",
       "22                            Taimyrskii Dolgano-Nenecki\n",
       "23                                                 Opeth\n",
       "24     United States presidential election in Kentuck...\n",
       "25                                            Greg Kells\n",
       "26                                Flickan i jordkallaren\n",
       "27                                             Jack Buck\n",
       "28                  Simon Dallas Cairns, 6th Earl Cairns\n",
       "29                      Nalgonda (Assembly constituency)\n",
       "                             ...                        \n",
       "970                                       Dale L. Walker\n",
       "971                                     Synuchus minimus\n",
       "972                             Dubielno, Chełmno County\n",
       "973                                  Coleophora wockella\n",
       "974     1984 NCAA Division I Men's Ice Hockey Tournament\n",
       "975                                        Bryant Walker\n",
       "976                 Nunkeeling, East Riding of Yorkshire\n",
       "977                                 William Calvin Chase\n",
       "978                     Farm to Market Road 1749 (Texas)\n",
       "979    Terminal Marítimo de Passageiros do Porto Inte...\n",
       "980                                     Roman picaresque\n",
       "981          List of Super Bantamweight boxing champions\n",
       "982                                               Purdum\n",
       "983                                           Crosmieres\n",
       "984                                      Charlie Bingham\n",
       "985                            Back to Back: Raw & Uncut\n",
       "986                                         Alex Chapple\n",
       "987                                            Yaw Angle\n",
       "988                           Boys and Girls Clubs Wales\n",
       "989                                 Crossroads, Kentucky\n",
       "990                                          Tree Lizard\n",
       "991                             John Rennie, (1761-1821)\n",
       "992                                       Northern Crown\n",
       "993                                    Chasmina tibialis\n",
       "994                  Maldah Medical College and Hospital\n",
       "995                                  Virginia State Song\n",
       "996                                       Yuri Lisianski\n",
       "997                                Phytophthora phaseoli\n",
       "998                           Church of john the baptist\n",
       "999                   Orange County Courthouse (Indiana)\n",
       "Name: article, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fln_df[:1000][\"article\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 151 ms per loop\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The occult</th>\n",
       "      <th>Of/pertaining to events/occurrences</th>\n",
       "      <th>Aspects of emotion</th>\n",
       "      <th>Wrongdoing</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>Military equipment</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Transfer of property</th>\n",
       "      <th>Inhabitant</th>\n",
       "      <th>Armed forces</th>\n",
       "      <th>...</th>\n",
       "      <th>Types of laws</th>\n",
       "      <th>Reptiles</th>\n",
       "      <th>Hunting</th>\n",
       "      <th>Means of travel</th>\n",
       "      <th>Chordates</th>\n",
       "      <th>Exercise of authority</th>\n",
       "      <th>Victory</th>\n",
       "      <th>Relinquishing</th>\n",
       "      <th>Doing</th>\n",
       "      <th>Attack with aircraft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 376 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [The occult, Of/pertaining to events/occurrences, Aspects of emotion, Wrongdoing, Difficulty, Military equipment, Frequency, Transfer of property, Inhabitant, Armed forces, Moral evil, Lack of power/authority, Enquiry, Working, People collectively, Earth science, Suffering, Reading, Love, Supply, Particular time, Industry, Failure/lack of success, Region of the earth, Buying, Necessity, Removing from dwelling, Trader, Chemistry, Motion in specific manner, Transport, War, Wholeness, Compassion, Fashionableness, Drill/training, Animals collectively, Punishment, Memory, In a ripening manner, Knowledge, Hearing/noise, Restlessness, Pride, Attention, Merchandise, Ethnicities, By family relationships, Trading conditions, Languages of the world, Variety/species, Office, Ill-health, Customs/values/civilization, Relationship, By nature, Providing with dwelling, Navigation, Bad taste, Causation, Possessions, Discovery, The paranormal, Bodily movement, Kind/sort, Duty/obligation, Barter, Furnishing with inhabitants, Calmness, Anthropocentrism, Suitable time/opportunity, Place of education, Study of society, Appearance of plant, Geodetic references, Healing/cure, Naming, Military power, By day or by night, Shape, Water, Brokerage, Position/job, Correspondence, Intelligibility, Rightness/justice, Fees and taxes, Poverty, Violent emotion, Locomotive, Advantage, Undertaking, Acquisition, Source/principle of life, Invertebrates, Thought, Social event, Business affairs, Amending, Zeal/enthusiasm, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 376 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try adding zeros to dataframe to see if it's simply a memory issue\n",
    "\n",
    "pd.DataFrame(fln_df[:1000][\"article\"].map(get_category_freq_list), columns=categories_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 147 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "pd.DataFrame.from_items(fln_df[:1000][\"article\"].map(get_category_freq_list).items(), \n",
    "                        columns=categories_list, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# runtime ~3min\n",
    "test_single_df = pd.DataFrame(fln_df.index.map(get_category_freq_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277504</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277505</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277506</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277507</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277508</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277509</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277510</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277511</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277512</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277513</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277514</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277515</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277516</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277517</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277518</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277519</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277520</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277521</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277522</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277523</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277524</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277525</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277526</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277527</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277528</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277529</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277530</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277531</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277532</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277533</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11277534 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          0\n",
       "0         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "2         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "3         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "4         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "5         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "6         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "7         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "8         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "9         [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "10        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "12        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "13        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "14        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "15        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "16        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "17        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "18        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "19        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "20        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "21        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "22        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "23        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "24        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "25        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "26        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "27        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "28        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "29        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "...                                                     ...\n",
       "11277504  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11277505  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11277506  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11277507  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11277508  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11277509  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11277510  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11277511  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11277512  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11277513  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11277514  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11277515  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11277516  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11277517  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11277518  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11277519  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11277520  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11277521  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11277522  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11277523  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11277524  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11277525  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11277526  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11277527  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11277528  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11277529  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11277530  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11277531  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11277532  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "11277533  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "\n",
       "[11277534 rows x 1 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_single_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 112 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "pd.DataFrame([x for x in fln_df[:1000].index.map(get_category_freq_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_df = pd.DataFrame(fln_df[:1000].index.map(get_category_freq_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.int64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36m_asarray_tuplesafe\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m   2007\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (1000,376) into shape (1000)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-12e5ffdf68c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[1;32m   3970\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3971\u001b[0m                         \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3972\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3973\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3974\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_apply_standard\u001b[0;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[1;32m   4079\u001b[0m                 \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4081\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4082\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    224\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    225\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_init_dict\u001b[0;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         return _arrays_to_mgr(arrays, data_names, index, columns,\n\u001b[0;32m--> 363\u001b[0;31m                               dtype=dtype)\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     def _init_ndarray(self, values, index, columns, dtype=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m   5161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5162\u001b[0m     \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5163\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_homogenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5165\u001b[0m     \u001b[0;31m# from BlockManager perspective\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_homogenize\u001b[0;34m(data, index, dtype)\u001b[0m\n\u001b[1;32m   5475\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_multiget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5476\u001b[0m             v = _sanitize_array(v, index, dtype=dtype, copy=False,\n\u001b[0;32m-> 5477\u001b[0;31m                                 raise_cast_failure=False)\n\u001b[0m\u001b[1;32m   5478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5479\u001b[0m         \u001b[0mhomogenized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_sanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m   2885\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data must be 1-dimensional'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2886\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2887\u001b[0;31m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_tuplesafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2889\u001b[0m     \u001b[0;31m# This is to prevent mixed-type Series getting all casted to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36m_asarray_tuplesafe\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m   2009\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m                 \u001b[0;31m# we have a list-of-list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2011\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2009\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m                 \u001b[0;31m# we have a list-of-list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2011\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.int64' object is not iterable"
     ]
    }
   ],
   "source": [
    "t_df.apply(lambda x: pd.DataFrame([i for i in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.2\n",
      "0.3\n",
      "0.4\n",
      "0.5\n",
      "0.6\n",
      "0.7\n",
      "0.8\n",
      "0.9\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# iteratively write data to csv\n",
    "\n",
    "path = \"/Users/mark/Desktop/temp_data/\"\n",
    "\n",
    "with open(path + \"articles_rows_by_columns_categories.txt\", \"a\") as myfile:\n",
    " \n",
    "    n = 0\n",
    "    stop = 100000\n",
    "\n",
    "    for count in yield_category_counts(fln_df):\n",
    "        n += 1\n",
    "        if n % int(stop/10) == 0:\n",
    "            print(n / stop)\n",
    "        myfile.write(\",\".join([str(x) for x in count]))\n",
    "        if n > stop:\n",
    "            break\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.from_csv(path + \"articles_rows_by_columns_categories.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FAILED (TOO MUCH MEMORY)\n",
    "# runtime ~ (started 6:10)\n",
    "    # warning: eats up a lot of memory\n",
    "categories_count_df = pd.DataFrame([x for x in fln_df.index.map(get_category_freq_list)])\n",
    "categories_count_df.columns = categories_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# join category count to dataframe\n",
    "\n",
    "pd.concat(fln_df, categories_count_df, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write dataframe to disk "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
